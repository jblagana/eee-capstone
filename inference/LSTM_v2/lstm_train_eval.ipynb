{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7449,"status":"ok","timestamp":1711781225264,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"Vwx4g5bE-fBq"},"outputs":[],"source":["import sys\n","import copy\n","import torch\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def count(my_array):\n","    # Initialize the count\n","    norm_count = 0\n","    ano_count = 0\n","\n","    # Iterate through each element in the list\n","    for id in my_array:\n","        if 'normal' in id:\n","            norm_count += 1\n","        elif 'anomaly' in id:\n","            ano_count += 1\n","\n","    return (ano_count, norm_count)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1173,"status":"ok","timestamp":1711781229130,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"03fJ1Ifz_Xx5"},"outputs":[],"source":["n_features = 6  # Number of features\n","sequence_length = 20  # Length of each sequence\n","\n","df = pd.read_csv('train_inf5050_skip5.csv')\n","video_ids = df['video_id'].unique()\n","\n","# Split video IDs into train, validation, and test sets\n","train_ids, test_ids = train_test_split(video_ids, test_size=0.3, random_state=42)\n","val_ids = np.concatenate((train_ids[:len(test_ids)], test_ids[:int(0.5*len(test_ids))]))\n","\n","train_ano_norm = count(train_ids)\n","val_ano_norm = count(val_ids)\n","test_ano_norm = count(test_ids)\n","\n","print('training (anomaly, normal): ', train_ano_norm)\n","# print('validation (anomaly, normal): ', val_ano_norm)\n","print('testing (anomaly, normal): ', test_ano_norm)\n","\n","X_train = []\n","y_train = []\n","\n","X_val = []\n","y_val = []\n","\n","X_test = []\n","y_test = []\n","\n","\n","for train_id in train_ids:\n","    filtered_df = df[df['video_id'] == train_id]\n","    features = filtered_df[['crowd_density', 'loitering', 'no_concealment', 'low_concealment', 'med_concealment', 'high_concealment']]\n","    RBP = filtered_df['rbp'].iloc[0]\n","    features = features.to_numpy()\n","    n_seq = len(features) // sequence_length\n","\n","    # Reshape the features into batches\n","    features = features[:sequence_length * n_seq].reshape(-1, sequence_length, n_features) # one video is one batch\n","    labels = [RBP] * n_seq\n","\n","    # Extend the lists\n","    X_train.extend(features)\n","    y_train.extend(labels)\n","\n","\n","for val_id in val_ids:\n","    filtered_df = df[df['video_id'] == val_id]\n","    features = filtered_df[['crowd_density', 'loitering', 'no_concealment', 'low_concealment', 'med_concealment', 'high_concealment']]\n","    RBP = filtered_df['rbp'].iloc[0]\n","    features = features.to_numpy()\n","    n_seq = len(features) // sequence_length\n","\n","    # Reshape the features into batches\n","    features = features[:sequence_length * n_seq].reshape(-1, sequence_length, n_features) # one video is one batch\n","    labels = [RBP] * n_seq\n","\n","    # Extend the lists\n","    X_val.extend(features)\n","    y_val.extend(labels)\n","\n","\n","test_n_seq = dict()\n","for test_id in test_ids:\n","    filtered_df = df[df['video_id'] == test_id]\n","    features = filtered_df[['video_id', 'frame_num', 'crowd_density', 'loitering', 'no_concealment', 'low_concealment', 'med_concealment', 'high_concealment']]\n","    RBP = filtered_df['rbp'].iloc[0]\n","    features = features.to_numpy()\n","    n_seq = len(features) // sequence_length\n","    test_n_seq[test_id] = n_seq\n","\n","\n","    # Reshape the features into batches\n","    features = features[:sequence_length * n_seq].reshape(-1, sequence_length, n_features+2) # one video is one batch\n","    labels = [RBP] * n_seq\n","\n","    # Extend the lists\n","    X_test.extend(features)\n","    y_test.extend(labels)\n","\n","# Convert to NumPy arrays\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n","\n","X_val = np.array(X_val)\n","y_val = np.array(y_val)\n","\n","X_test = np.array(X_test)\n","y_test = np.array(y_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_test_features = X_test[:, :, 2:] # features only\n","X_test_id = X_test[:, :,  :2] # id and frame number"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711781232513,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"_JIe90qW_T1a"},"outputs":[],"source":["# Normalize features\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train.reshape(-1, n_features)).reshape(-1, sequence_length, n_features)\n","X_val_scaled = scaler.transform(X_val.reshape(-1, n_features)).reshape(-1, sequence_length, n_features)\n","X_test_scaled = scaler.transform(X_test_features.reshape(-1, n_features)).reshape(-1, sequence_length, n_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1711781232514,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"X5eDa7lG_cny"},"outputs":[],"source":["# Convert data to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n","X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n","y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n","\n","X_test = np.concatenate((X_test_id, X_test_tensor.reshape(-1, sequence_length, n_features)), axis=2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(LSTMModel, self).__init__()\n","        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, 1)  # Single output neuron for binary classification\n","        self.sigmoid = nn.Sigmoid()  # Sigmoid activation for binary classification\n","\n","    def forward(self, x):\n","        out, _ = self.lstm1(x)\n","        out = self.fc(out[:, -1, :])  # Use the last hidden state for prediction (summary)\n","        out = self.sigmoid(out) # Apply sigmoid activation\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# class LSTMModel(nn.Module):\n","#     def __init__(self, input_size, hidden_size):\n","#         super(LSTMModel, self).__init__()\n","#         self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n","#         self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)  # Additional LSTM layer\n","#         self.fc1 = nn.Linear(hidden_size, 64)  # First dense layer\n","#         self.fc2 = nn.Linear(64, 32)  # Second dense layer\n","#         self.fc3 = nn.Linear(32, 1)  # Single output neuron\n","#         self.fc4 = nn.Sigmoid()  # Sigmoid activation for binary classification\n","\n","#     def forward(self, x):\n","#         out, (h_n, c_n) = self.lstm1(x)\n","#         out, _ = self.lstm2(out, (h_n, c_n))  # Pass through the second LSTM layer\n","#         out = self.fc1(out[:, -1, :])\n","#         out = self.fc2(out)\n","#         out = self.fc3(out)\n","#         out = self.fc4(out)\n","#         return out"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6041,"status":"ok","timestamp":1711781241254,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"J3lqeR3_Bljc"},"outputs":[],"source":["# Instantiate the model\n","input_size = n_features\n","hidden_size = 64\n","model = LSTMModel(input_size, hidden_size)\n","\n","# Define loss function and optimizer\n","# criterion = nn.MSELoss()-------------------------------------------\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize empty lists to store training losses\n","train_losses = []\n","val_losses = []\n","val_loss_temp = float('inf')\n","\n","# Training loop\n","n_epochs = 300\n","patience = og_patience = 100\n","\n","for epoch in range(1, n_epochs+1):\n","    model.train()\n","    optimizer.zero_grad()\n","    outputs = model(X_train_tensor)\n","    loss = criterion(outputs, y_train_tensor.unsqueeze(1))\n","    loss.backward()\n","    optimizer.step()\n","\n","\n","    # Validation\n","    model.eval()\n","    with torch.no_grad():\n","        val_outputs = model(X_test_tensor)\n","        val_loss = criterion(val_outputs, y_test_tensor.unsqueeze(1))\n","\n","    # Append losses to lists\n","    train_losses.append(loss.item())\n","    val_losses.append(val_loss.item())\n","\n","    # save best model\n","    if val_loss.item() < val_loss_temp:\n","        best_model, best_epoch = copy.deepcopy(model), epoch\n","        val_loss_temp = val_loss.item()\n","        patience = og_patience + 1\n","\n","    patience -= 1\n","    if patience == 0:\n","        print(f\"\\nNo progress in the last {og_patience} epochs. Training completed.\")\n","        break\n","    \n","    # print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n","\n","    # Training progress bar\n","    label = f\"{epoch}/{n_epochs} epochs | val_loss = {val_loss.item():.4f}\"\n","    progress = (epoch)/ n_epochs\n","    progress_bar_len = 50\n","    filled_len = int(progress_bar_len * progress)\n","    bar = '=' * filled_len + '-' * (progress_bar_len - filled_len)\n","    sys.stdout.write(f'\\rTraining in progress: [{bar}] {progress * 100:.1f}% [{label}]')\n","    sys.stdout.flush()\n","\n","# Plot the losses\n","plt.figure(figsize=(8, 6))\n","plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Training Loss\")\n","plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training and Validation Losses\")\n","plt.grid(True)\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = best_model\n","print(f\"Best model at epoch {best_epoch}.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Create an instance of the LSTM model\n","# model = LSTMModel(n_features, hidden_size=64)\n","\n","# # Load the saved weights\n","# model.load_state_dict(torch.load('lstm_model_0.485.pt'))\n","# model.eval()  # Set the model to evaluation mode\n","# optimal_threshold = 0.485"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":811,"status":"ok","timestamp":1711781253468,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"_rkNTTRjB3YY"},"outputs":[],"source":["# Save the model\n","# torch.save(model.state_dict(), f'lstm_model_skip5_{optimal_threshold:.3f}.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Find optimal threshold based on best F1-score\n","thresholds = np.arange(0, 1, 0.001)\n","precision = 0\n","recall = 0\n","f1_score = 0\n","f1_scores = []\n","optimal_threshold = 0\n","excluded_thresholds = []\n","\n","for j, threshold in enumerate(thresholds):\n","    verdict = ''\n","    temp_vid_id = ''\n","    TP = FP = TN = FN = 0\n","\n","    # Iterate through sequences\n","    seq_counter = 0\n","    for i, sequence in enumerate(X_test):\n","        input_data = torch.tensor(sequence[:, 2:].astype(np.float32), dtype=torch.float32)\n","        vid_id, frame_num = sequence[sequence_length-1, 0], sequence[sequence_length-1, 1]  # ID and frame of last row in the sequence\n","        \n","        # Check if it's the same video ID as before\n","        if vid_id == temp_vid_id:\n","            continue  # Ignore sequences from the same video if robbery prediction was already done\n","        \n","        # Make predictions\n","        with torch.no_grad():\n","            output = model(input_data.unsqueeze(0))  # Add batch dimension\n","            RBP = (output).squeeze().cpu().numpy()\n","\n","        actualRBP = y_test[i]\n","\n","        # Print progress bar\n","        n_seq = test_n_seq[vid_id]\n","\n","\n","        # Evaluate predictions\n","        if ((RBP >= threshold) & (actualRBP == 1)):\n","            verdict = 'TP'\n","            TP += 1\n","            temp_vid_id = vid_id\n","            seq_counter = 0\n","        elif ((RBP >= threshold) & (actualRBP == 0)):\n","            verdict = 'FP'\n","            FP += 1\n","            temp_vid_id = vid_id\n","            seq_counter = 0\n","        elif ((RBP < threshold) & (actualRBP == 0)):\n","            verdict = 'TN'\n","            seq_counter += 1\n","        elif ((RBP < threshold) & (actualRBP == 1)):\n","            verdict = 'FN'\n","            seq_counter += 1\n","\n","        if seq_counter == n_seq:\n","            seq_counter = 0\n","            if verdict == 'TN':\n","                TN += 1\n","            else:\n","                FN += 1\n","    \n","    try:\n","        precision = TP / (TP+FP)\n","        recall = TP / (TP+FN)\n","        f1_score = 2*(precision*recall)/(precision+recall)\n","\n","        if not (f1_scores):\n","            best_f1_score = f1_score\n","            optimal_threshold = threshold\n","            best_TP = TP\n","            best_TN = TN\n","            best_FP = FP\n","            best_FN = FN\n","        elif f1_score > best_f1_score:\n","            best_f1_score = f1_score\n","            optimal_threshold = threshold\n","            best_TP = TP\n","            best_TN = TN\n","            best_FP = FP\n","            best_FN = FN\n","\n","        f1_scores.append(f1_score)\n","        f1_score = f'{f1_score:.3f}'\n","\n","\n","    except:\n","        excluded_thresholds.append(threshold)\n","        f1_score = None\n","    \n","    best_f1_score = round(best_f1_score, 4)\n","    optimal_threshold = round(optimal_threshold, 3)\n","\n","\n","     # Evaluation progress bar\n","    label = f\"th = {threshold:.3f} | BEST: f1 = {best_f1_score} @ th = {optimal_threshold}\"\n","    progress = (j+1)/ len(thresholds)\n","    progress_bar_len = 50\n","    filled_len = int(progress_bar_len * progress)\n","    bar = '=' * filled_len + '-' * (progress_bar_len - filled_len)\n","    sys.stdout.write(f'\\rDetermining optimal threshold: [{bar}] {progress * 100:.1f}% [{label}]')\n","    sys.stdout.flush()\n","\n","print(f\"\\nBest f1-score: {best_f1_score}\")\n","print(f\"optimal threshold: {optimal_threshold}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filtered_thresholds = thresholds[~np.isin(thresholds, excluded_thresholds)]\n","\n","# Plot the F1 curve\n","plt.figure(figsize=(8, 6))\n","plt.plot(filtered_thresholds, f1_scores, label=\"F1-scores\")\n","plt.xlabel(\"Threshold\")\n","plt.ylabel(\"F1-score\")\n","plt.title(\"F1 Curve\")\n","plt.grid(True)\n","\n","# Add vertical dashed red line at the optimal threshold\n","plt.axvline(x=optimal_threshold, color='red', linestyle='--', label=f\"Optimal Threshold ({optimal_threshold:.2f})\")\n","\n","# Annotate the intersection point\n","plt.scatter(optimal_threshold, best_f1_score, color='red', marker='o')\n","plt.annotate(f\"({optimal_threshold:.2f}, {best_f1_score:.3f})\", xy=(optimal_threshold, best_f1_score),\n","             xytext=(optimal_threshold + 0.01, best_f1_score - 0.005), color='red')\n","\n","# Add legend in the lower left corner\n","plt.legend(loc='lower left')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the confusion matrix\n","conf_matrix = np.array([[best_TN, best_FP],\n","                         [best_FN, best_TP]])\n","\n","# # Create the confusion matrix\n","# conf_matrix = np.array([[TN, FP],\n","#                          [FN, TP]])\n","\n","# Transpose the matrix\n","conf_matrix_transposed = conf_matrix.T\n","\n","# Plot the transposed confusion matrix\n","plt.imshow(conf_matrix_transposed, cmap='Blues', interpolation='nearest')\n","plt.colorbar()\n","plt.xticks([0, 1], ['normal', 'robbery'])  # Set custom x-axis labels\n","plt.yticks([0, 1], ['normal', 'robbery'], rotation='vertical')  # Set custom y-axis labels\n","\n","# Add text annotations\n","for i in range(2):\n","    for j in range(2):\n","        plt.text(j, i, str(conf_matrix_transposed[i, j]), ha='center', va='center', color='black')\n","\n","plt.title('Confusion Matrix for Best F1-score')\n","plt.xlabel('True Label')  # Add x-axis label\n","plt.ylabel('Predicted Label')  # Add y-axis label\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize variables\n","skip = 5 # skipped frames in scripting\n","verdict = ''\n","temp_vid_id = ''\n","TP = FP = TN = FN = 0\n","\n","# Iterate through sequences\n","seq_counter = 0\n","for i, sequence in enumerate(X_test):\n","    input_data = torch.tensor(sequence[:, 2:].astype(np.float32), dtype=torch.float32)\n","    vid_id, frame_num = sequence[sequence_length-1, 0], sequence[sequence_length-1, 1]  # ID and frame of last row in the sequence\n","    \n","    # Check if it's the same video ID as before\n","    if vid_id == temp_vid_id:\n","        continue  # Ignore sequences from the same video if robbery prediction was already done\n","    \n","    # Make predictions\n","    with torch.no_grad():\n","        output = model(input_data.unsqueeze(0))  # Add batch dimension\n","        RBP = (output).squeeze().cpu().numpy()\n","\n","    actualRBP = y_test[i]\n","\n","    # Print progress bar\n","    n_seq = test_n_seq[vid_id]\n","\n","\n","    # Evaluate predictions\n","    if ((RBP >= optimal_threshold) & (actualRBP == 1)):\n","        verdict = 'TP'\n","        TP += 1\n","        temp_vid_id = vid_id\n","        seq_counter = 0\n","        print(f\"\\n{vid_id} | TRUE POSITIVE | ROBBERY correctly predicted @ {(frame_num*100/(n_seq*sequence_length*skip)):.4f}% of video.\")\n","    elif ((RBP >= optimal_threshold) & (actualRBP == 0)):\n","        verdict = 'FP'\n","        FP += 1\n","        temp_vid_id = vid_id\n","        seq_counter = 0\n","        print(f\"\\n{vid_id} | FALSE POSITIVE | ROBBERY wrongly predicted @ {(frame_num*100/(n_seq*sequence_length*skip)):.4f}% of video.\")\n","    elif ((RBP < optimal_threshold) & (actualRBP == 0)):\n","        verdict = 'TN'\n","        seq_counter += 1\n","    elif ((RBP < optimal_threshold) & (actualRBP == 1)):\n","        verdict = 'FN'\n","        seq_counter += 1\n","\n","    if seq_counter == n_seq:\n","        seq_counter = 0\n","        if verdict == 'TN':\n","            TN += 1\n","            print(f\"\\n{vid_id} | TRUE NEGATIVE | NO ROBBERY correctly predicted.\")\n","        else:\n","            FN += 1\n","            print(f\"\\n{vid_id} | FALSE NEGATIVE | NO ROBBERY wrongly predicted.\")\n","\n","print(f'\\nTP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}')\n","\n","try:\n","    precision = TP / (TP+FP)\n","    recall = TP / (TP+FN)\n","    f1_score = 2*(precision*recall)/(precision+recall)\n","except:\n","    threshold\n","\n","print(f'Precision = {precision}, Recall = {recall}, F1-score = {f1_score}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Find optimal threshold based on BEST ACCURACY\n","# thresholds = np.arange(0.001, 1, 0.001)\n","# accuracy = 0\n","# accuracies = []\n","# optimal_threshold = 0\n","# excluded_thresholds = []\n","\n","# for j, threshold in enumerate(thresholds):\n","#     verdict = ''\n","#     temp_vid_id = ''\n","#     TP = FP = TN = FN = 0\n","\n","#     # Iterate through sequences\n","#     seq_counter = 0\n","#     for i, sequence in enumerate(X_test):\n","#         input_data = torch.tensor(sequence[:, 2:].astype(np.float32), dtype=torch.float32)\n","#         vid_id, frame_num = sequence[sequence_length-1, 0], sequence[sequence_length-1, 1]  # ID and frame of last row in the sequence\n","        \n","#         # Check if it's the same video ID as before\n","#         if vid_id == temp_vid_id:\n","#             continue  # Ignore sequences from the same video if robbery prediction was already done\n","        \n","#         # Make predictions\n","#         with torch.no_grad():\n","#             output = model(input_data.unsqueeze(0))  # Add batch dimension\n","#             RBP = (output).squeeze().cpu().numpy()\n","\n","#         actualRBP = y_test[i]\n","\n","#         # Print progress bar\n","#         n_seq = test_n_seq[vid_id]\n","\n","\n","#         # Evaluate predictions\n","#         if ((RBP >= threshold) & (actualRBP == 1)):\n","#             verdict = 'TP'\n","#             TP += 1\n","#             temp_vid_id = vid_id\n","#             seq_counter = 0\n","#         elif ((RBP >= threshold) & (actualRBP == 0)):\n","#             verdict = 'FP'\n","#             FP += 1\n","#             temp_vid_id = vid_id\n","#             seq_counter = 0\n","#         elif ((RBP < threshold) & (actualRBP == 0)):\n","#             verdict = 'TN'\n","#             seq_counter += 1\n","#         elif ((RBP < threshold) & (actualRBP == 1)):\n","#             verdict = 'FN'\n","#             seq_counter += 1\n","\n","#         if seq_counter == n_seq:\n","#             seq_counter = 0\n","#             if verdict == 'TN':\n","#                 TN += 1\n","#             else:\n","#                 FN += 1\n","    \n","#     try:\n","#         accuracy = (TP+TN)/(TP+TN+FP+FN)\n","\n","#         if not (accuracies):\n","#             best_accuracy = accuracy\n","#             optimal_threshold = threshold\n","#             best_TP = TP\n","#             best_TN = TN\n","#             best_FP = FP\n","#             best_FN = FN\n","#         elif accuracy > best_accuracy:\n","#             best_accuracy = accuracy\n","#             optimal_threshold = threshold\n","#             best_TP = TP\n","#             best_TN = TN\n","#             best_FP = FP\n","#             best_FN = FN\n","\n","#         accuracies.append(accuracy)\n","#         accuracy = f'{accuracy:.3f}'\n","\n","#     except:\n","#         excluded_thresholds.append(threshold)\n","#         # accuracy = None\n","    \n","\n","#      # Evaluation progress bar\n","#     label = f\"th = {threshold:.3f} | BEST: accuracy = {best_accuracy:.3f} @ th = {optimal_threshold:.3f}\"\n","#     progress = (j+1)/ len(thresholds)\n","#     progress_bar_len = 50\n","#     filled_len = int(progress_bar_len * progress)\n","#     bar = '=' * filled_len + '-' * (progress_bar_len - filled_len)\n","#     sys.stdout.write(f'\\rDetermining optimal threshold: [{bar}] {progress * 100:.1f}% [{label}]')\n","#     sys.stdout.flush()\n","\n","# print(f\"\\nBest accuracy: {best_accuracy}\")\n","# print(f\"optimal threshold: {optimal_threshold}\")\n","\n","\n","\n","\n","\n","# # Plot the f1 curve\n","# filtered_thresholds = thresholds[~np.isin(thresholds, excluded_thresholds)]\n","# plt.figure(figsize=(8, 6))\n","# plt.plot(filtered_thresholds, accuracies)\n","# plt.xlabel(\"Threshold\")\n","# plt.ylabel(\"Accuracy\")\n","# plt.title(\"Accuracy Curve\")\n","# plt.grid(True)\n","# plt.show()\n","\n","\n","\n","\n","# # Create the confusion matrix\n","# conf_matrix = np.array([[best_TN, best_FP],\n","#                          [best_FN, best_TP]])\n","\n","# # Transpose the matrix\n","# conf_matrix_transposed = conf_matrix.T\n","\n","# # Plot the transposed confusion matrix\n","# plt.imshow(conf_matrix_transposed, cmap='Blues', interpolation='nearest')\n","# plt.colorbar()\n","# plt.xticks([0, 1], ['normal', 'robbery'])  # Set custom x-axis labels\n","# plt.yticks([0, 1], ['normal', 'robbery'], rotation='vertical')  # Set custom y-axis labels\n","\n","# # Add text annotations\n","# for i in range(2):\n","#     for j in range(2):\n","#         plt.text(j, i, str(conf_matrix_transposed[i, j]), ha='center', va='center', color='black')\n","\n","# plt.title('Confusion Matrix for Best Accuracy')\n","# plt.xlabel('True Label')  # Add x-axis label\n","# plt.ylabel('Predicted Label')  # Add y-axis label\n","# plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Find optimal threshold based on BEST PRECISION\n","# thresholds = np.arange(0.01, 1, 0.01)\n","# precision = 0\n","# precisions = []\n","# recall = 0\n","# f1_score = 0\n","# f1_scores = []\n","# optimal_threshold = 0\n","# excluded_thresholds = []\n","\n","# for j, threshold in enumerate(thresholds):\n","#     verdict = ''\n","#     temp_vid_id = ''\n","#     TP = FP = TN = FN = 0\n","\n","#     # Iterate through sequences\n","#     seq_counter = 0\n","#     for i, sequence in enumerate(X_test):\n","#         input_data = torch.tensor(sequence[:, 2:].astype(np.float32), dtype=torch.float32)\n","#         vid_id, frame_num = sequence[sequence_length-1, 0], sequence[sequence_length-1, 1]  # ID and frame of last row in the sequence\n","        \n","#         # Check if it's the same video ID as before\n","#         if vid_id == temp_vid_id:\n","#             continue  # Ignore sequences from the same video if robbery prediction was already done\n","        \n","#         # Make predictions\n","#         with torch.no_grad():\n","#             output = model(input_data.unsqueeze(0))  # Add batch dimension\n","#             RBP = (output).squeeze().cpu().numpy()\n","\n","#         actualRBP = y_test[i]\n","\n","#         # Print progress bar\n","#         n_seq = test_n_seq[vid_id]\n","\n","\n","#         # Evaluate predictions\n","#         if ((RBP >= threshold) & (actualRBP == 1)):\n","#             verdict = 'TP'\n","#             TP += 1\n","#             temp_vid_id = vid_id\n","#             seq_counter = 0\n","#         elif ((RBP >= threshold) & (actualRBP == 0)):\n","#             verdict = 'FP'\n","#             FP += 1\n","#             temp_vid_id = vid_id\n","#             seq_counter = 0\n","#         elif ((RBP < threshold) & (actualRBP == 0)):\n","#             verdict = 'TN'\n","#             seq_counter += 1\n","#         elif ((RBP < threshold) & (actualRBP == 1)):\n","#             verdict = 'FN'\n","#             seq_counter += 1\n","\n","#         if seq_counter == n_seq:\n","#             seq_counter = 0\n","#             if verdict == 'TN':\n","#                 TN += 1\n","#             else:\n","#                 FN += 1\n","    \n","#     try:\n","#         precision = TP / (TP+FP)\n","#         # recall = TP / (TP+FN)\n","#         # f1_score = 2*(precision*recall)/(precision+recall)\n","\n","#         if not (precisions):\n","#             best_precision = precision\n","#             # best_f1_score = f1_score\n","#             optimal_threshold = threshold\n","#             best_TP = TP\n","#             best_TN = TN\n","#             best_FP = FP\n","#             best_FN = FN\n","#         elif precision > best_precision:\n","#             best_precision = precision\n","#             # best_f1_score = f1_score\n","#             optimal_threshold = threshold\n","#             best_TP = TP\n","#             best_TN = TN\n","#             best_FP = FP\n","#             best_FN = FN\n","\n","#         # f1_scores.append(f1_score)\n","#         # f1_score = f'{f1_score:.3f}'\n","\n","#         # Based on precision\n","#         precisions.append(precision)\n","#         precision = f'{precision:.3f}'\n","\n","#     except:\n","#         excluded_thresholds.append(threshold)\n","#         # f1_score = None\n","    \n","\n","#      # Evaluation progress bar\n","#     # label = f\"th = {threshold:.2f} | BEST: f1 = {best_f1_score} @ th = {optimal_threshold}\"\n","#     label = f\"th = {threshold:.3f} | BEST: prec = {best_precision:.3f} @ th = {optimal_threshold:.3f}\"\n","#     progress = (j+1)/ len(thresholds)\n","#     progress_bar_len = 50\n","#     filled_len = int(progress_bar_len * progress)\n","#     bar = '=' * filled_len + '-' * (progress_bar_len - filled_len)\n","#     sys.stdout.write(f'\\rDetermining optimal threshold: [{bar}] {progress * 100:.1f}% [{label}]')\n","#     sys.stdout.flush()\n","\n","# print(f\"\\nBest precision: {best_precision}\")\n","# print(f\"optimal threshold: {optimal_threshold}\")\n","\n","\n","\n","# filtered_thresholds = thresholds[~np.isin(thresholds, excluded_thresholds)]\n","\n","# # Plot the f1 curve\n","# plt.figure(figsize=(8, 6))\n","# plt.plot(filtered_thresholds, f1_scores)\n","# plt.xlabel(\"Threshold\")\n","# plt.ylabel(\"Precision\")\n","# plt.title(\"Precision Curve\")\n","# plt.grid(True)\n","# plt.show()\n","\n","\n","\n","# # Create the confusion matrix\n","# conf_matrix = np.array([[best_TN, best_FP],\n","#                          [best_FN, best_TP]])\n","\n","# # Transpose the matrix\n","# conf_matrix_transposed = conf_matrix.T\n","\n","# # Plot the transposed confusion matrix\n","# plt.imshow(conf_matrix_transposed, cmap='Blues', interpolation='nearest')\n","# plt.colorbar()\n","# plt.xticks([0, 1], ['normal', 'robbery'])  # Set custom x-axis labels\n","# plt.yticks([0, 1], ['normal', 'robbery'], rotation='vertical')  # Set custom y-axis labels\n","\n","# # Add text annotations\n","# for i in range(2):\n","#     for j in range(2):\n","#         plt.text(j, i, str(conf_matrix_transposed[i, j]), ha='center', va='center', color='black')\n","\n","# plt.title('Confusion Matrix for Best Precision')\n","# plt.xlabel('True Label')  # Add x-axis label\n","# plt.ylabel('Predicted Label')  # Add y-axis label\n","# plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPMU7dohBYF5DlsgRyJrE/O","mount_file_id":"1_vcn38GyssYpiQMLJxkUNLTHQ0DQiy4R","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
