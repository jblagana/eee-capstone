{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lstm_model import LSTMModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file\n",
    "data_path = \"data.csv\"\n",
    "features = pd.read_csv(data_path, usecols=['crowd_density', 'crowd_count', 'loitering', 'low_concealment', 'med_concealment', 'high_concealment'])\n",
    "\n",
    "# Batch size is variable\n",
    "sequence_length = 20  # Adjust as needed\n",
    "n_features = 6\n",
    "\n",
    "features = features.to_numpy()\n",
    "\n",
    "# Calculate the number of batches\n",
    "n_seq = len(features) // sequence_length\n",
    "\n",
    "# Reshape the features into batches\n",
    "input_data = features[:sequence_length*n_seq].reshape(-1, sequence_length, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 6\n",
    "sequence_length = 20\n",
    "\n",
    "input_data = np.random.rand(sequence_length, n_features)\n",
    "actualRBP = np.random.randint(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm1): LSTM(6, 64, batch_first=True)\n",
       "  (lstm2): LSTM(64, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (fc4): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the LSTM model\n",
    "model = LSTMModel(n_features, hidden_size=64)\n",
    "\n",
    "# Load the saved weights\n",
    "model.load_state_dict(torch.load('model_0.5068858861923218.pt'))\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.53 | actual: robbery | CORRECT\n",
      "prediction: 0.50 | actual: robbery \n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.53 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery \n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.51 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT\n",
      "prediction: 0.52 | actual: robbery | CORRECT"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "input_data = scaler.fit_transform(input_data)\n",
    "input_data = input_data.tolist()\n",
    "input_data = torch.tensor(input_data, dtype=torch.float32)\n",
    "\n",
    "# Ensure input shape matches\n",
    "if input_data.shape != (sequence_length, n_features):\n",
    "    print('error: ', f'Input shape must be {(sequence_length, n_features)}. Yours has shape {input_data.shape}')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    output = model(input_data.unsqueeze(0))  # Add batch dimension\n",
    "    RBP = (output).squeeze().cpu().numpy()\n",
    "\n",
    "label = [\"no robbery\", \"robbery\"]\n",
    "optimal_threshold = 0.50688588 #--------------------------------------\n",
    "\n",
    "print(f\"\\nprediction: {label[int(RBP >= optimal_threshold)]} | actual: {label[actualRBP]}\", end=\" \")\n",
    "if ((RBP >= optimal_threshold) & (actualRBP == 1)) | ((RBP < optimal_threshold) & (actualRBP == 0)):\n",
    "    print(\"| CORRECT\", end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
