{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7449,"status":"ok","timestamp":1711781225264,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"Vwx4g5bE-fBq"},"outputs":[],"source":["import seaborn as sns\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import sys\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_recall_curve\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1173,"status":"ok","timestamp":1711781229130,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"03fJ1Ifz_Xx5"},"outputs":[],"source":["# # Generate synthetic sequential data\n","n_samples = 100\n","n_features = 6\n","sequence_length = 100\n","\n","# Generate random features\n","features = np.random.rand(n_samples, sequence_length, n_features)\n","labels = np.random.randint(0, 2, size=n_samples)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1711781229130,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"PVQKz1EK-nEp"},"outputs":[],"source":["# Split data into train, validation, and test sets\n","X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.3, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711781232513,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"_JIe90qW_T1a"},"outputs":[{"ename":"ValueError","evalue":"cannot reshape array of size 420 into shape (100,6)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Normalize features\u001b[39;00m\n\u001b[0;32m      2\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m----> 3\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m X_val_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_val\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_features))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, sequence_length, n_features)\n\u001b[0;32m      5\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_features))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, sequence_length, n_features)\n","\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 420 into shape (100,6)"]}],"source":["# Normalize features\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train.reshape(-1, n_features)).reshape(-1, sequence_length, n_features)\n","X_val_scaled = scaler.transform(X_val.reshape(-1, n_features)).reshape(-1, sequence_length, n_features)\n","X_test_scaled = scaler.transform(X_test.reshape(-1, n_features)).reshape(-1, sequence_length, n_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1711781232514,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"X5eDa7lG_cny"},"outputs":[],"source":["# Convert data to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n","X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n","y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(LSTMModel, self).__init__()\n","        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n","        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)  # Additional LSTM layer\n","        self.fc1 = nn.Linear(hidden_size, 64)  # First dense layer\n","        self.fc2 = nn.Linear(64, 32)  # Second dense layer\n","        self.fc3 = nn.Linear(32, 1)  # Single output neuron\n","        self.fc4 = nn.Sigmoid()  # Sigmoid activation for binary classification\n","\n","    def forward(self, x):\n","        out, (h_n, c_n) = self.lstm1(x)\n","        out, _ = self.lstm2(out, (h_n, c_n))  # Pass through the second LSTM layer\n","        out = self.fc1(out[:, -1, :])\n","        out = self.fc2(out)\n","        out = self.fc3(out)\n","        out = self.fc4(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6041,"status":"ok","timestamp":1711781241254,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"J3lqeR3_Bljc"},"outputs":[],"source":["# Instantiate the model\n","input_size = n_features\n","hidden_size = 64\n","model = LSTMModel(input_size, hidden_size)\n","\n","# Define loss function and optimizer\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize empty lists to store training and validation losses\n","train_losses = []\n","val_losses = []\n","\n","# Training loop\n","n_epochs = 10\n","for epoch in range(n_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","    outputs = model(X_train_tensor)\n","    loss = criterion(outputs, y_train_tensor.unsqueeze(1))\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Validation\n","    model.eval()\n","    with torch.no_grad():\n","        val_outputs = model(X_val_tensor)\n","        val_loss = criterion(val_outputs, y_val_tensor.unsqueeze(1))\n","\n","    # Append losses to lists\n","    train_losses.append(loss.item())\n","    val_losses.append(val_loss.item())\n","\n","    # print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n","    # Training progress bar\n","    label = f\"{epoch+1}/{n_epochs} epochs\"\n","    progress = (epoch+1)/ n_epochs\n","    progress_bar_len = 50\n","    filled_len = int(progress_bar_len * progress)\n","    bar = '=' * filled_len + '-' * (progress_bar_len - filled_len)\n","    sys.stdout.write(f'\\rTraining in progress: [{bar}] {progress * 100:.1f}% [{label}]')\n","    sys.stdout.flush()\n","\n","\n","# Plot the losses\n","plt.figure(figsize=(8, 6))\n","plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Training Loss\")\n","plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training and Validation Losses\")\n","plt.grid(True)\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1711781241766,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"fJQKe1N9B1Y8","outputId":"bc401f36-8d9d-47bb-a07c-dfbb34eeda77"},"outputs":[],"source":["# Evaluate on test set\n","model.eval()\n","with torch.no_grad():\n","    test_outputs = model(X_test_tensor)\n","\n","    test_loss = criterion(test_outputs, y_test_tensor.unsqueeze(1))\n","    print(f\"Test Loss: {test_loss.item():.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluation\n","precision, recall, thresholds = precision_recall_curve(y_test_tensor, test_outputs)\n","\n","# Calculate F1 scores for each threshold\n","f1_scores = 2 * (precision * recall) / (precision + recall)\n","\n","# Find the optimal threshold that maximizes the F1 score\n","optimal_threshold = thresholds[f1_scores.argmax()]\n","max_f1_score = f1_scores.max()\n","\n","print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n","print(f\"Max F1 Score: {max_f1_score:.4f}\")\n","\n","# Plot the F1 curve and the vertical line for the optimal threshold\n","plt.figure(figsize=(12, 6))\n","\n","# F1 curve\n","plt.subplot(1, 2, 1)\n","plt.plot(thresholds, f1_scores[:-1], label='F1 Score')\n","plt.axvline(x=optimal_threshold, color='r', linestyle='--', label='Optimal Threshold')\n","plt.xlabel('Threshold')\n","plt.ylabel('F1 Score')\n","plt.title('F1 Curve')\n","plt.grid(True)\n","plt.legend()\n","\n","# Confusion matrix\n","plt.subplot(1, 2, 2)\n","test_outputs = (test_outputs >= optimal_threshold).float()\n","cm = confusion_matrix(y_test_tensor, test_outputs)\n","labels = ['No Robbery', 'Robbery']\n","cm_transposed = cm.T\n","\n","sns.heatmap(cm_transposed, annot=True, fmt='d', cmap='Blues', cbar=False,\n","            xticklabels=labels, yticklabels=labels)\n","plt.title('Confusion Matrix')\n","plt.xlabel('True Labels')\n","plt.ylabel('Predicted Labels')\n","\n","plt.tight_layout()  # Adjust spacing between subplots\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":811,"status":"ok","timestamp":1711781253468,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"_rkNTTRjB3YY"},"outputs":[],"source":["# Save the model\n","torch.save(model.state_dict(), f'model_{optimal_threshold}.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1711781263339,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"U8W9-bPaCNdL","outputId":"a8ee009e-c313-46a3-c129-1d44d23edb91"},"outputs":[],"source":["# Create an instance of your LSTM model\n","# model = LSTMModel(input_size, hidden_size)\n","\n","# # Load the saved weights\n","# model.load_state_dict(torch.load('model_0.5527.pt'))\n","# model.eval()  # Set the model to evaluation mode"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(int(n_samples*0.15)):\n","\n","    input_data = X_test[i]\n","\n","    # Preprocess data\n","    input_data = scaler.fit_transform(input_data.reshape(-1, n_features)).reshape(-1, sequence_length, n_features)[0]\n","    input_data = input_data.tolist()\n","    input_data = torch.tensor(input_data, dtype=torch.float32)\n","\n","    # Ensure input shape matches\n","    if input_data.shape != (sequence_length, n_features):\n","        print('error: ', f'Input shape must be {(sequence_length, n_features)}. Yours has shape {input_data.shape}')\n","\n","    # Make predictions\n","    with torch.no_grad():\n","        output = model(input_data.unsqueeze(0))  # Add batch dimension\n","        RBP = (output).squeeze().cpu().numpy()\n","\n","    actualRBP = y_test[i]\n","\n","    print(f\"\\nprediction: {RBP:.2f} | actual: {actualRBP}\", end=\" \")\n","    if ((RBP >= optimal_threshold) & (actualRBP == 1)) | ((RBP < optimal_threshold) & (actualRBP == 0)):\n","        print(\"| CORRECT\", end=\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# IF NEEDED\n","\n","# # Plot the precision-recall curve\n","# plt.figure(figsize=(8, 6))\n","# plt.plot(recall, precision, label='Precision-Recall Curve')\n","# plt.xlabel('Recall')\n","# plt.ylabel('Precision')\n","# plt.title('Precision-Recall Curve')\n","# plt.grid(True)\n","# plt.legend()\n","# plt.show()\n","\n","# # Plot the F1 curve\n","# plt.figure(figsize=(8, 6))\n","# plt.plot(thresholds, f1_scores[:-1], label='F1 Score')\n","# plt.axvline(x=optimal_threshold, color='r', linestyle='--', label='Optimal Threshold')\n","# plt.xlabel('Threshold')\n","# plt.ylabel('F1 Score')\n","# plt.title('F1 Curve')\n","# plt.grid(True)\n","# plt.legend()\n","# plt.show()\n","\n","# # Plot the Confusion matrix\n","# test_outputs = (test_outputs >= optimal_threshold).float()  # Convert probabilities to 0 or 1\n","# # test_outputs.squeeze(-1)\n","\n","# cm = confusion_matrix(y_test_tensor, test_outputs)\n","# labels = ['No Robbery', 'Robbery']\n","\n","# # Transpose the confusion matrix and swap axis labels\n","# cm_transposed = cm.T\n","\n","# plt.figure(figsize=(8, 6))\n","# sns.heatmap(cm_transposed, annot=True, fmt='d', cmap='Blues', cbar=False,\n","#             xticklabels=labels, yticklabels=labels)  # Set labels for x and y axes\n","# plt.title('Confusion Matrix')\n","# plt.xlabel('True Labels')\n","# plt.ylabel('Predicted Labels')\n","# plt.show()\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPMU7dohBYF5DlsgRyJrE/O","mount_file_id":"1_vcn38GyssYpiQMLJxkUNLTHQ0DQiy4R","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
