{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7449,"status":"ok","timestamp":1711781225264,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"Vwx4g5bE-fBq"},"outputs":[],"source":["import seaborn as sns\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import sys\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_recall_curve\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1173,"status":"ok","timestamp":1711781229130,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"03fJ1Ifz_Xx5"},"outputs":[],"source":["# # Generate synthetic sequential data\n","n_samples = 100\n","n_features = 3\n","sequence_length = 20\n","\n","# Generate random features\n","features = np.random.rand(n_samples, sequence_length, n_features)\n","labels = np.random.randint(0, 2, size=n_samples)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1711781229130,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"PVQKz1EK-nEp"},"outputs":[],"source":["# Split data into train, validation, and test sets\n","X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.3, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711781232513,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"_JIe90qW_T1a"},"outputs":[],"source":["# Normalize features\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train.reshape(-1, n_features)).reshape(-1, sequence_length, n_features)\n","X_val_scaled = scaler.transform(X_val.reshape(-1, n_features)).reshape(-1, sequence_length, n_features)\n","X_test_scaled = scaler.transform(X_test.reshape(-1, n_features)).reshape(-1, sequence_length, n_features)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1711781232514,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"X5eDa7lG_cny"},"outputs":[],"source":["# Convert data to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n","X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n","y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(LSTMModel, self).__init__()\n","        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n","        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)  # Additional LSTM layer\n","        self.fc1 = nn.Linear(hidden_size, 64)  # First dense layer\n","        self.fc2 = nn.Linear(64, 32)  # Second dense layer\n","        self.fc3 = nn.Linear(32, 1)  # Single output neuron\n","        self.fc4 = nn.Sigmoid()  # Sigmoid activation for binary classification\n","\n","    def forward(self, x):\n","        out, (h_n, c_n) = self.lstm1(x)\n","        out, _ = self.lstm2(out, (h_n, c_n))  # Pass through the second LSTM layer\n","        out = self.fc1(out[:, -1, :])\n","        out = self.fc2(out)\n","        out = self.fc3(out)\n","        out = self.fc4(out)\n","        return out"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6041,"status":"ok","timestamp":1711781241254,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"J3lqeR3_Bljc"},"outputs":[],"source":["# Instantiate the model\n","input_size = n_features\n","hidden_size = 64\n","output_size = 1\n","model = LSTMModel(input_size, hidden_size)\n","\n","# Define loss function and optimizer\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/100], Loss: 0.2483, Val Loss: 0.2541\n","Training in progress: [--------------------------------------------------] 1.0% [1/100 epochs]Epoch [2/100], Loss: 0.2481, Val Loss: 0.2548\n","Training in progress: [=-------------------------------------------------] 2.0% [2/100 epochs]Epoch [3/100], Loss: 0.2479, Val Loss: 0.2552\n","Training in progress: [=-------------------------------------------------] 3.0% [3/100 epochs]Epoch [4/100], Loss: 0.2478, Val Loss: 0.2555\n","Training in progress: [==------------------------------------------------] 4.0% [4/100 epochs]Epoch [5/100], Loss: 0.2477, Val Loss: 0.2555\n","Training in progress: [==------------------------------------------------] 5.0% [5/100 epochs]Epoch [6/100], Loss: 0.2475, Val Loss: 0.2553\n","Training in progress: [===-----------------------------------------------] 6.0% [6/100 epochs]Epoch [7/100], Loss: 0.2472, Val Loss: 0.2550\n","Training in progress: [===-----------------------------------------------] 7.0% [7/100 epochs]Epoch [8/100], Loss: 0.2469, Val Loss: 0.2546\n","Training in progress: [====----------------------------------------------] 8.0% [8/100 epochs]Epoch [9/100], Loss: 0.2466, Val Loss: 0.2542\n","Training in progress: [====----------------------------------------------] 9.0% [9/100 epochs]Epoch [10/100], Loss: 0.2461, Val Loss: 0.2538\n","Training in progress: [=====---------------------------------------------] 10.0% [10/100 epochs]Epoch [11/100], Loss: 0.2456, Val Loss: 0.2535\n","Training in progress: [=====---------------------------------------------] 11.0% [11/100 epochs]Epoch [12/100], Loss: 0.2449, Val Loss: 0.2532\n","Training in progress: [======--------------------------------------------] 12.0% [12/100 epochs]Epoch [13/100], Loss: 0.2442, Val Loss: 0.2531\n","Training in progress: [======--------------------------------------------] 13.0% [13/100 epochs]Epoch [14/100], Loss: 0.2432, Val Loss: 0.2531\n","Training in progress: [=======-------------------------------------------] 14.0% [14/100 epochs]Epoch [15/100], Loss: 0.2420, Val Loss: 0.2534\n","Training in progress: [=======-------------------------------------------] 15.0% [15/100 epochs]Epoch [16/100], Loss: 0.2407, Val Loss: 0.2538\n","Training in progress: [========------------------------------------------] 16.0% [16/100 epochs]Epoch [17/100], Loss: 0.2391, Val Loss: 0.2543\n","Training in progress: [========------------------------------------------] 17.0% [17/100 epochs]Epoch [18/100], Loss: 0.2373, Val Loss: 0.2547\n","Training in progress: [=========-----------------------------------------] 18.0% [18/100 epochs]Epoch [19/100], Loss: 0.2354, Val Loss: 0.2548\n","Training in progress: [=========-----------------------------------------] 19.0% [19/100 epochs]Epoch [20/100], Loss: 0.2332, Val Loss: 0.2549\n","Training in progress: [==========----------------------------------------] 20.0% [20/100 epochs]Epoch [21/100], Loss: 0.2308, Val Loss: 0.2554\n","Training in progress: [==========----------------------------------------] 21.0% [21/100 epochs]Epoch [22/100], Loss: 0.2282, Val Loss: 0.2566\n","Training in progress: [===========---------------------------------------] 22.0% [22/100 epochs]Epoch [23/100], Loss: 0.2254, Val Loss: 0.2582\n","Training in progress: [===========---------------------------------------] 23.0% [23/100 epochs]Epoch [24/100], Loss: 0.2224, Val Loss: 0.2598\n","Training in progress: [============--------------------------------------] 24.0% [24/100 epochs]Epoch [25/100], Loss: 0.2194, Val Loss: 0.2613\n","Training in progress: [============--------------------------------------] 25.0% [25/100 epochs]Epoch [26/100], Loss: 0.2165, Val Loss: 0.2633\n","Training in progress: [=============-------------------------------------] 26.0% [26/100 epochs]Epoch [27/100], Loss: 0.2138, Val Loss: 0.2671\n","Training in progress: [=============-------------------------------------] 27.0% [27/100 epochs]Epoch [28/100], Loss: 0.2115, Val Loss: 0.2731\n","Training in progress: [==============------------------------------------] 28.0% [28/100 epochs]Epoch [29/100], Loss: 0.2097, Val Loss: 0.2808\n","Training in progress: [==============------------------------------------] 29.0% [29/100 epochs]Epoch [30/100], Loss: 0.2084, Val Loss: 0.2890\n","Training in progress: [===============-----------------------------------] 30.0% [30/100 epochs]Epoch [31/100], Loss: 0.2075, Val Loss: 0.2971\n","Training in progress: [===============-----------------------------------] 31.0% [31/100 epochs]Epoch [32/100], Loss: 0.2070, Val Loss: 0.3040\n","Training in progress: [================----------------------------------] 32.0% [32/100 epochs]Epoch [33/100], Loss: 0.2064, Val Loss: 0.3083\n","Training in progress: [================----------------------------------] 33.0% [33/100 epochs]Epoch [34/100], Loss: 0.2053, Val Loss: 0.3096\n","Training in progress: [=================---------------------------------] 34.0% [34/100 epochs]Epoch [35/100], Loss: 0.2035, Val Loss: 0.3085\n","Training in progress: [=================---------------------------------] 35.0% [35/100 epochs]Epoch [36/100], Loss: 0.2013, Val Loss: 0.3061\n","Training in progress: [==================--------------------------------] 36.0% [36/100 epochs]Epoch [37/100], Loss: 0.1992, Val Loss: 0.3034\n","Training in progress: [==================--------------------------------] 37.0% [37/100 epochs]Epoch [38/100], Loss: 0.1976, Val Loss: 0.3012\n","Training in progress: [===================-------------------------------] 38.0% [38/100 epochs]Epoch [39/100], Loss: 0.1964, Val Loss: 0.2998\n","Training in progress: [===================-------------------------------] 39.0% [39/100 epochs]Epoch [40/100], Loss: 0.1955, Val Loss: 0.2993\n","Training in progress: [====================------------------------------] 40.0% [40/100 epochs]Epoch [41/100], Loss: 0.1945, Val Loss: 0.2998\n","Training in progress: [====================------------------------------] 41.0% [41/100 epochs]Epoch [42/100], Loss: 0.1935, Val Loss: 0.3014\n","Training in progress: [=====================-----------------------------] 42.0% [42/100 epochs]Epoch [43/100], Loss: 0.1923, Val Loss: 0.3043\n","Training in progress: [=====================-----------------------------] 43.0% [43/100 epochs]Epoch [44/100], Loss: 0.1909, Val Loss: 0.3082\n","Training in progress: [======================----------------------------] 44.0% [44/100 epochs]Epoch [45/100], Loss: 0.1893, Val Loss: 0.3127\n","Training in progress: [======================----------------------------] 45.0% [45/100 epochs]Epoch [46/100], Loss: 0.1876, Val Loss: 0.3176\n","Training in progress: [=======================---------------------------] 46.0% [46/100 epochs]Epoch [47/100], Loss: 0.1858, Val Loss: 0.3227\n","Training in progress: [=======================---------------------------] 47.0% [47/100 epochs]Epoch [48/100], Loss: 0.1839, Val Loss: 0.3278\n","Training in progress: [========================--------------------------] 48.0% [48/100 epochs]Epoch [49/100], Loss: 0.1818, Val Loss: 0.3322\n","Training in progress: [========================--------------------------] 49.0% [49/100 epochs]Epoch [50/100], Loss: 0.1795, Val Loss: 0.3358\n","Training in progress: [=========================-------------------------] 50.0% [50/100 epochs]Epoch [51/100], Loss: 0.1767, Val Loss: 0.3385\n","Training in progress: [=========================-------------------------] 51.0% [51/100 epochs]Epoch [52/100], Loss: 0.1734, Val Loss: 0.3407\n","Training in progress: [==========================------------------------] 52.0% [52/100 epochs]Epoch [53/100], Loss: 0.1696, Val Loss: 0.3426\n","Training in progress: [==========================------------------------] 53.0% [53/100 epochs]Epoch [54/100], Loss: 0.1655, Val Loss: 0.3443\n","Training in progress: [===========================-----------------------] 54.0% [54/100 epochs]Epoch [55/100], Loss: 0.1612, Val Loss: 0.3458\n","Training in progress: [===========================-----------------------] 55.0% [55/100 epochs]Epoch [56/100], Loss: 0.1571, Val Loss: 0.3476\n","Training in progress: [============================----------------------] 56.0% [56/100 epochs]Epoch [57/100], Loss: 0.1531, Val Loss: 0.3493\n","Training in progress: [============================----------------------] 57.0% [57/100 epochs]Epoch [58/100], Loss: 0.1492, Val Loss: 0.3506\n","Training in progress: [============================----------------------] 58.0% [58/100 epochs]Epoch [59/100], Loss: 0.1453, Val Loss: 0.3517\n","Training in progress: [=============================---------------------] 59.0% [59/100 epochs]Epoch [60/100], Loss: 0.1415, Val Loss: 0.3505\n","Training in progress: [==============================--------------------] 60.0% [60/100 epochs]Epoch [61/100], Loss: 0.1394, Val Loss: 0.3446\n","Training in progress: [==============================--------------------] 61.0% [61/100 epochs]Epoch [62/100], Loss: 0.1363, Val Loss: 0.3453\n","Training in progress: [===============================-------------------] 62.0% [62/100 epochs]Epoch [63/100], Loss: 0.1316, Val Loss: 0.3451\n","Training in progress: [===============================-------------------] 63.0% [63/100 epochs]Epoch [64/100], Loss: 0.1297, Val Loss: 0.3453\n","Training in progress: [================================------------------] 64.0% [64/100 epochs]Epoch [65/100], Loss: 0.1251, Val Loss: 0.3491\n","Training in progress: [================================------------------] 65.0% [65/100 epochs]Epoch [66/100], Loss: 0.1203, Val Loss: 0.3504\n","Training in progress: [=================================-----------------] 66.0% [66/100 epochs]Epoch [67/100], Loss: 0.1168, Val Loss: 0.3535\n","Training in progress: [=================================-----------------] 67.0% [67/100 epochs]Epoch [68/100], Loss: 0.1125, Val Loss: 0.3574\n","Training in progress: [==================================----------------] 68.0% [68/100 epochs]Epoch [69/100], Loss: 0.1100, Val Loss: 0.3562\n","Training in progress: [==================================----------------] 69.0% [69/100 epochs]Epoch [70/100], Loss: 0.1068, Val Loss: 0.3590\n","Training in progress: [===================================---------------] 70.0% [70/100 epochs]Epoch [71/100], Loss: 0.1028, Val Loss: 0.3637\n","Training in progress: [===================================---------------] 71.0% [71/100 epochs]Epoch [72/100], Loss: 0.1003, Val Loss: 0.3684\n","Training in progress: [====================================--------------] 72.0% [72/100 epochs]Epoch [73/100], Loss: 0.0973, Val Loss: 0.3696\n","Training in progress: [====================================--------------] 73.0% [73/100 epochs]Epoch [74/100], Loss: 0.0947, Val Loss: 0.3721\n","Training in progress: [=====================================-------------] 74.0% [74/100 epochs]Epoch [75/100], Loss: 0.0918, Val Loss: 0.3779\n","Training in progress: [=====================================-------------] 75.0% [75/100 epochs]Epoch [76/100], Loss: 0.0890, Val Loss: 0.3766\n","Training in progress: [======================================------------] 76.0% [76/100 epochs]Epoch [77/100], Loss: 0.0858, Val Loss: 0.3752\n","Training in progress: [======================================------------] 77.0% [77/100 epochs]Epoch [78/100], Loss: 0.0825, Val Loss: 0.3761\n","Training in progress: [=======================================-----------] 78.0% [78/100 epochs]Epoch [79/100], Loss: 0.0779, Val Loss: 0.3840\n","Training in progress: [=======================================-----------] 79.0% [79/100 epochs]Epoch [80/100], Loss: 0.0741, Val Loss: 0.3899\n","Training in progress: [========================================----------] 80.0% [80/100 epochs]Epoch [81/100], Loss: 0.0726, Val Loss: 0.3776\n","Training in progress: [========================================----------] 81.0% [81/100 epochs]Epoch [82/100], Loss: 0.0709, Val Loss: 0.3799\n","Training in progress: [=========================================---------] 82.0% [82/100 epochs]Epoch [83/100], Loss: 0.0660, Val Loss: 0.3846\n","Training in progress: [=========================================---------] 83.0% [83/100 epochs]Epoch [84/100], Loss: 0.0640, Val Loss: 0.3810\n","Training in progress: [==========================================--------] 84.0% [84/100 epochs]Epoch [85/100], Loss: 0.0584, Val Loss: 0.3704\n","Training in progress: [==========================================--------] 85.0% [85/100 epochs]Epoch [86/100], Loss: 0.0605, Val Loss: 0.3957\n","Training in progress: [===========================================-------] 86.0% [86/100 epochs]Epoch [87/100], Loss: 0.0544, Val Loss: 0.4278\n","Training in progress: [===========================================-------] 87.0% [87/100 epochs]Epoch [88/100], Loss: 0.0523, Val Loss: 0.4006\n","Training in progress: [============================================------] 88.0% [88/100 epochs]Epoch [89/100], Loss: 0.0424, Val Loss: 0.3737\n","Training in progress: [============================================------] 89.0% [89/100 epochs]Epoch [90/100], Loss: 0.0443, Val Loss: 0.4139\n","Training in progress: [=============================================-----] 90.0% [90/100 epochs]Epoch [91/100], Loss: 0.0422, Val Loss: 0.4352\n","Training in progress: [=============================================-----] 91.0% [91/100 epochs]Epoch [92/100], Loss: 0.0328, Val Loss: 0.4751\n","Training in progress: [==============================================----] 92.0% [92/100 epochs]Epoch [93/100], Loss: 0.0305, Val Loss: 0.5212\n","Training in progress: [==============================================----] 93.0% [93/100 epochs]Epoch [94/100], Loss: 0.0431, Val Loss: 0.4547\n","Training in progress: [===============================================---] 94.0% [94/100 epochs]Epoch [95/100], Loss: 0.0367, Val Loss: 0.4362\n","Training in progress: [===============================================---] 95.0% [95/100 epochs]Epoch [96/100], Loss: 0.0460, Val Loss: 0.3945\n","Training in progress: [================================================--] 96.0% [96/100 epochs]Epoch [97/100], Loss: 0.0515, Val Loss: 0.3924\n","Training in progress: [================================================--] 97.0% [97/100 epochs]Epoch [98/100], Loss: 0.0461, Val Loss: 0.3897\n","Training in progress: [=================================================-] 98.0% [98/100 epochs]Epoch [99/100], Loss: 0.0374, Val Loss: 0.4141\n","Training in progress: [=================================================-] 99.0% [99/100 epochs]Epoch [100/100], Loss: 0.0337, Val Loss: 0.4914\n","Training in progress: [==================================================] 100.0% [100/100 epochs]"]}],"source":["# Initialize empty lists to store training and validation losses\n","train_losses = []\n","val_losses = []\n","\n","# Training loop\n","n_epochs = 100\n","for epoch in range(n_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","    outputs = model(X_train_tensor)\n","    loss = criterion(outputs, y_train_tensor.unsqueeze(1))\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Validation\n","    model.eval()\n","    with torch.no_grad():\n","        val_outputs = model(X_val_tensor)\n","        val_loss = criterion(val_outputs, y_val_tensor.unsqueeze(1))\n","\n","    # Append losses to lists\n","    train_losses.append(loss.item())\n","    val_losses.append(val_loss.item())\n","\n","    # print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n","    # Training progress bar\n","    label = f\"{epoch+1}/{n_epochs} epochs\"\n","    progress = (epoch+1)/ n_epochs\n","    progress_bar_len = 50\n","    filled_len = int(progress_bar_len * progress)\n","    bar = '=' * filled_len + '-' * (progress_bar_len - filled_len)\n","    sys.stdout.write(f'\\rTraining in progress: [{bar}] {progress * 100:.1f}% [{label}]')\n","    sys.stdout.flush()\n","\n","\n","# Plot the losses\n","# plt.figure(figsize=(8, 6))\n","# plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Training Loss\")\n","# plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\")\n","# plt.xlabel(\"Epoch\")\n","# plt.ylabel(\"Loss\")\n","# plt.title(\"Training and Validation Losses\")\n","# plt.grid(True)\n","# plt.legend()\n","# plt.show()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1711781241766,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"fJQKe1N9B1Y8","outputId":"bc401f36-8d9d-47bb-a07c-dfbb34eeda77"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Loss: 0.3753\n"]}],"source":["# Evaluate on test set\n","model.eval()\n","with torch.no_grad():\n","    test_outputs = model(X_test_tensor)\n","\n","    test_loss = criterion(test_outputs, y_test_tensor.unsqueeze(1))\n","    print(f\"Test Loss: {test_loss.item():.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluation\n","precision, recall, thresholds = precision_recall_curve(y_test_tensor, test_outputs)\n","\n","# Calculate F1 scores for each threshold\n","f1_scores = 2 * (precision * recall) / (precision + recall)\n","\n","# Find the optimal threshold that maximizes the F1 score\n","optimal_threshold = thresholds[f1_scores.argmax()]\n","max_f1_score = f1_scores.max()\n","\n","print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n","print(f\"Max F1 Score: {max_f1_score:.4f}\")\n","\n","# # Plot the precision-recall curve\n","# plt.figure(figsize=(8, 6))\n","# plt.plot(recall, precision, label='Precision-Recall Curve')\n","# plt.xlabel('Recall')\n","# plt.ylabel('Precision')\n","# plt.title('Precision-Recall Curve')\n","# plt.grid(True)\n","# plt.legend()\n","# plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the F1 curve\n","# plt.figure(figsize=(8, 6))\n","# plt.plot(thresholds, f1_scores[:-1], label='F1 Score')\n","# plt.axvline(x=optimal_threshold, color='r', linestyle='--', label='Optimal Threshold')\n","# plt.xlabel('Threshold')\n","# plt.ylabel('F1 Score')\n","# plt.title('F1 Curve')\n","# plt.grid(True)\n","# plt.legend()\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the Confusion matrix\n","\n","# test_outputs = (test_outputs >= optimal_threshold).float()  # Convert probabilities to 0 or 1\n","# # test_outputs.squeeze(-1)\n","\n","# cm = confusion_matrix(y_test_tensor, test_outputs)\n","# labels = ['No Robbery', 'Robbery']\n","\n","# # Transpose the confusion matrix and swap axis labels\n","# cm_transposed = cm.T\n","\n","# plt.figure(figsize=(8, 6))\n","# sns.heatmap(cm_transposed, annot=True, fmt='d', cmap='Blues', cbar=False,\n","#             xticklabels=labels, yticklabels=labels)  # Set labels for x and y axes\n","# plt.title('Confusion Matrix')\n","# plt.xlabel('True Labels')\n","# plt.ylabel('Predicted Labels')\n","# plt.show()"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":811,"status":"ok","timestamp":1711781253468,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"_rkNTTRjB3YY"},"outputs":[],"source":["# from datetime import datetime\n","\n","# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","# Save the model with the time stamp in the file name\n","torch.save(model.state_dict(), f'model.pt')\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1711781263339,"user":{"displayName":"Jan Rhey Lagaña","userId":"10820671969604914994"},"user_tz":-480},"id":"U8W9-bPaCNdL","outputId":"a8ee009e-c313-46a3-c129-1d44d23edb91"},"outputs":[{"data":{"text/plain":["LSTMModel(\n","  (lstm1): LSTM(3, 64, batch_first=True)\n","  (lstm2): LSTM(64, 64, batch_first=True)\n","  (fc1): Linear(in_features=64, out_features=64, bias=True)\n","  (fc2): Linear(in_features=64, out_features=32, bias=True)\n","  (fc3): Linear(in_features=32, out_features=1, bias=True)\n","  (fc4): Sigmoid()\n",")"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Create an instance of your LSTM model\n","model = LSTMModel(input_size, hidden_size)\n","\n","# Load the saved weights\n","model.load_state_dict(torch.load('model.pt'))\n","model.eval()  # Set the model to evaluation mode"]},{"cell_type":"markdown","metadata":{"id":"oB4e6TaGK0XE"},"source":["---------------------**Activate API Endpoint** before proceeding-------------------------"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Lae_LOWWJAXz"},"outputs":[],"source":["import requests\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," 0 RBP = 1.0 | actual RBP = 1 | CORRECT\n"," 1 RBP = 0.0 | actual RBP = 0 | CORRECT\n"," 2 RBP = 0.88 | actual RBP = 1 | CORRECT\n"," 3 RBP = 1.0 | actual RBP = 1 | CORRECT\n"," 4 RBP = 0.12 | actual RBP = 0 | CORRECT\n"," 5 RBP = 0.0 | actual RBP = 0 | CORRECT\n"," 6 RBP = 0.86 | actual RBP = 1 | CORRECT\n"," 7 RBP = 1.0 | actual RBP = 1 | CORRECT\n"," 8 RBP = 0.15 | actual RBP = 0 | CORRECT\n"," 9 RBP = 0.02 | actual RBP = 0 | CORRECT\n"," 10 RBP = 0.98 | actual RBP = 1 | CORRECT\n"," 11 RBP = 1.0 | actual RBP = 1 | CORRECT\n"," 12 RBP = 0.0 | actual RBP = 0 | CORRECT\n"," 13 RBP = 0.01 | actual RBP = 0 | CORRECT\n"," 14 RBP = 1.0 | actual RBP = 1 | CORRECT"]}],"source":["for i in range(int(n_samples*0.15)):\n","    input_data = {\n","    \"input\":  X_train_scaled.tolist()[i] \n","}\n","    response = requests.post('http://localhost:5000/predict', json=input_data).json()\n","\n","    threshold = 0.5\n","    RBP = float(f\"{response['output']:.2f}\")\n","    # RBP = 1\n","\n","    actualRBP = y_train.tolist()[i]\n","    print(\"\\n\", i, \"RBP =\", RBP, \"| actual RBP =\", actualRBP, end=\" \")\n","    # if RBP >= threshold:\n","    #     print(\"| WARNING! Impending robbery.\", end=\"\")\n","    if ((RBP >= threshold) & (actualRBP == 1)) | ((RBP < threshold) & (actualRBP == 0)):\n","        print(\"| CORRECT\", end=\"\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPMU7dohBYF5DlsgRyJrE/O","mount_file_id":"1_vcn38GyssYpiQMLJxkUNLTHQ0DQiy4R","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
